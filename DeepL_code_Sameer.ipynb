{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mdBU5Hgrm-a"
      },
      "source": [
        "## **Deep Learning for Causal Inference by Vikas Ramachandra**\n",
        "\n",
        "Applying the concepts from the \"Deep Learning for Causal Inference\" paper authored by Vikas Ramachandra to the data_for_churn_analysis dataset\n",
        "\n",
        "link to the paper: <a>https://arxiv.org/abs/1803.00149</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zvpIJP04rm-c",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# DA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ML\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_percentage_error, mean_absolute_error\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8SYz7N7arm-c",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Loading dataset\n",
        "df = pd.read_csv('data_for_churn_analysis.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQKDeQ46rm-c",
        "metadata": {},
        "outputId": "a070e69c-235e-4fb1-a49e-c49882c49c04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(104143, 18)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX90IDW1rm-d",
        "metadata": {},
        "outputId": "16c3563e-0cbd-4ea1-a88a-6accff434aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 104143 entries, 0 to 104142\n",
            "Data columns (total 18 columns):\n",
            " #   Column                                 Non-Null Count   Dtype  \n",
            "---  ------                                 --------------   -----  \n",
            " 0   device                                 104025 non-null  object \n",
            " 1   first_payment_amount                   104143 non-null  int64  \n",
            " 2   age                                    104001 non-null  float64\n",
            " 3   city                                   98301 non-null   object \n",
            " 4   number_of_cards                        103671 non-null  float64\n",
            " 5   payments_initiated                     103671 non-null  float64\n",
            " 6   payments_failed                        103671 non-null  float64\n",
            " 7   payments_completed                     103671 non-null  float64\n",
            " 8   payments_completed_amount_first_7days  103671 non-null  float64\n",
            " 9   reward_purchase_count_first_7days      80879 non-null   float64\n",
            " 10  coins_redeemed_first_7days             103671 non-null  float64\n",
            " 11  is_referral                            104143 non-null  bool   \n",
            " 12  visits_feature_1                       101497 non-null  float64\n",
            " 13  visits_feature_2                       101497 non-null  float64\n",
            " 14  given_permission_1                     104143 non-null  int64  \n",
            " 15  given_permission_2                     104143 non-null  int64  \n",
            " 16  user_id                                104143 non-null  int64  \n",
            " 17  is_churned                             104143 non-null  int64  \n",
            "dtypes: bool(1), float64(10), int64(5), object(2)\n",
            "memory usage: 13.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoV-zMYgrm-d",
        "outputId": "ea8ab164-100f-4f4e-c725-8b94394e5c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df.isnull().sum().sum()=37490\n",
            "perc of dataset missing 0.3599857887712088\n"
          ]
        }
      ],
      "source": [
        "# null values?\n",
        "print(f\"{df.isnull().sum().sum()=}\")\n",
        "print(f\"perc of dataset missing {df.isnull().sum().sum()/df.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgvZy3Ujrm-d",
        "outputId": "9b1e33a6-b7a0-40fe-87de-40e2c0094f4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "is_churned\n",
              "0    0.713192\n",
              "1    0.286808\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# proportion of people who have churned\n",
        "df['is_churned'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EqFfmVArm-d"
      },
      "source": [
        "### 1. **Impact of Referrals on Customer Acquisition and Retention**:\n",
        "   - Research Question: Do customers acquired through referrals (`is_referral`) exhibit different behaviors and retention rates compared to non-referred customers?\n",
        "   - Treatment: Customer acquisition through referrals\n",
        "   - Outcome: Customer behavior (e.g., `payments_initiated`, `payments_completed`, `visits_feature_1`, `visits_feature_2`) and churn (`is_churned`)\n",
        "   - Potential Confounders: `device`, `age`, `city`, `number_of_cards`, `payments_failed`, `payments_completed_amount_first_7days`, `reward_purchase_count_first_7days`, `coins_redeemed_first_7days`, `given_permission_1`, `given_permission_2`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEakGKKlrm-d"
      },
      "source": [
        "$$Y_i = f(T_i, X_i, \\epsilon_i)$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $Y_i$ represents the outcome variable `is_churned` for customer $i$\n",
        "- $T_i$ is the treatment variable `is_referral`, indicating whether customer $i$ was acquired through a referral\n",
        "- $X_i$ represents the vector of potential confounding variables for customer $i$, such as `device`, `age`, `city`, `number_of_cards`, `payments_failed`, `payments_completed_amount_first_7days`, `reward_purchase_count_first_7days`, `coins_redeemed_first_7days`, `given_permission_1`, `given_permission_2`\n",
        "- $\\epsilon_i$ is the error term, accounting for unobserved factors affecting the outcome\n",
        "- $f$ is an unknown function that maps the treatment, confounders, and error term to the outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Xvw_7xl1rm-d"
      },
      "outputs": [],
      "source": [
        "# -------------- DATA PREPROCESSING --------------------\n",
        "\n",
        "# Encoding using label encoding technique\n",
        "obj_cols = df.select_dtypes(include='object').columns # grabs object dtypes columns\n",
        "le = LabelEncoder() # creates LabelEncoder instance\n",
        "for col in obj_cols:\n",
        "    df[col] = le.fit_transform(df[col]) # encodes each column\n",
        "\n",
        "df['is_referral'] = np.where(df['is_referral'] == True, 1, 0)\n",
        "\n",
        "\n",
        "# -------------- IMPUTING MISSING VALUES --------------------\n",
        "missing_cols = df.columns[df.isna().any()].tolist()\n",
        "for col in missing_cols:\n",
        "    df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "\n",
        "# -------------- DATA SPLIT --------------------\n",
        "\n",
        "confounders = [\n",
        "    'device',\n",
        "    'age',\n",
        "    'city',\n",
        "    'number_of_cards',\n",
        "    'payments_failed',\n",
        "    'payments_completed_amount_first_7days',\n",
        "    'reward_purchase_count_first_7days',\n",
        "    'coins_redeemed_first_7days',\n",
        "    'given_permission_1',\n",
        "    'given_permission_2',\n",
        "    'is_referral' # treatment\n",
        "]\n",
        "\n",
        "y = df['is_churned']\n",
        "X = df[confounders]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "Y_train, Y_test = train_test_split(y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaMEkZ6rrm-e"
      },
      "source": [
        "### 1. **Generalized Neighbor Matching using Autoencoders**\n",
        "\n",
        "The paper proposes using autoencoders, a type of deep neural network, for dimensionality reduction while preserving the local neighborhood structure of the data. This is useful for generalized neighbor matching to estimate individual treatment effects (ITEs).\n",
        "\n",
        "The key points are:\n",
        "\n",
        "* In high dimensions, traditional neighbor matching methods like k-nearest neighbors struggle\n",
        "* Autoencoders can learn a low-dimensional representation that captures the manifold structure\n",
        "* This low-dimensional encoding preserves local neighborhoods for accurate neighbor identification\n",
        "* Experiments show autoencoders outperform methods like manifold learning for ITE estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mae_pca=0.28378702770176195\n"
          ]
        }
      ],
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Perform PCA for dimensionality reduction\n",
        "pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Compute nearest neighbors in the reduced-dimensional space obtained from PCA\n",
        "nbrs_pca = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(X_pca)\n",
        "distances_pca, indices_pca = nbrs_pca.kneighbors(X_test_pca)\n",
        "\n",
        "# Compute treatment effect using nearest neighbors in PCA space\n",
        "treatment_effect_pca = np.abs(Y_test.values - Y_train.iloc[indices_pca.flatten()])\n",
        "\n",
        "mae_pca = mean_absolute_error(Y_test, treatment_effect_pca)\n",
        "print(f\"{mae_pca=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Manifold Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this below takes a while to run for some reason"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Standardize the features\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # Perform TSNE for dimensionality reduction\n",
        "# tsne = TSNE(n_components=2)  # Reduce to 2 dimensions for visualization\n",
        "# X_tsne = tsne.fit_transform(X_scaled)\n",
        "# X_test_tsne = tsne.transform(X_test_scaled)\n",
        "\n",
        "# # Compute nearest neighbors in the reduced-dimensional space obtained from PCA\n",
        "# nbrs_pca = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(X_tsne)\n",
        "# distances_pca, indices_pca = nbrs_pca.kneighbors(X_test_tsne)\n",
        "\n",
        "# # Compute treatment effect using nearest neighbors in PCA space\n",
        "# treatment_effect_pca = np.abs(Y_test.values - Y_train.iloc[indices_pca.flatten()])\n",
        "\n",
        "# mae_tsne = mean_absolute_error(Y_test, treatment_effect_pca)\n",
        "# print(f\"{mae_tsne=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "VastVKpxrm-e"
      },
      "outputs": [],
      "source": [
        "input_dim = X.shape[1]  # Features count\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "\n",
        "# Encoder: Reduce dimensionality\n",
        "encoded_1 = Dense(64, activation='relu')(input_layer)\n",
        "encoded_2 = Dense(32, activation='relu')(encoded_1)\n",
        "encoded_3 = Dense(16, activation='relu')(encoded_2)\n",
        "encoded_4 = Dense(8, activation='relu')(encoded_3)\n",
        "\n",
        "# Decoder: Reconstruct the input\n",
        "decoded_1 = Dense(16, activation='relu')(encoded_4)\n",
        "decoded_2 = Dense(32, activation='relu')(decoded_1)\n",
        "decoded_3 = Dense(64, activation='relu')(decoded_2)\n",
        "decoded_4 = Dense(input_dim, activation='linear')(decoded_3)  # Final output layer\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoded_4)  # Ensure to output from the last decoding layer\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey_7YBXBrm-e",
        "outputId": "976cfc0b-d297-41b1-84e6-bcd9005c5703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.7488 - val_loss: 0.1669\n",
            "Epoch 2/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1682 - val_loss: 0.1611\n",
            "Epoch 3/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1590 - val_loss: 0.1609\n",
            "Epoch 4/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1556 - val_loss: 0.1666\n",
            "Epoch 5/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1572 - val_loss: 0.1539\n",
            "Epoch 6/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1527 - val_loss: 0.1580\n",
            "Epoch 7/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1559 - val_loss: 0.1522\n",
            "Epoch 8/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1544 - val_loss: 0.1592\n",
            "Epoch 9/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1521 - val_loss: 0.1523\n",
            "Epoch 10/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1536 - val_loss: 0.1516\n",
            "Epoch 11/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1511 - val_loss: 0.1536\n",
            "Epoch 12/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1519 - val_loss: 0.1498\n",
            "Epoch 13/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1499 - val_loss: 0.1526\n",
            "Epoch 14/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1517 - val_loss: 0.1547\n",
            "Epoch 15/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1507 - val_loss: 0.1496\n",
            "Epoch 16/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1495 - val_loss: 0.1493\n",
            "Epoch 17/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1505 - val_loss: 0.1488\n",
            "Epoch 18/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1478 - val_loss: 0.1486\n",
            "Epoch 19/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1498 - val_loss: 0.1475\n",
            "Epoch 20/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1497 - val_loss: 0.1625\n",
            "Epoch 21/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1514 - val_loss: 0.1479\n",
            "Epoch 22/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1501 - val_loss: 0.1476\n",
            "Epoch 23/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1495 - val_loss: 0.1470\n",
            "Epoch 24/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1477 - val_loss: 0.1489\n",
            "Epoch 25/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1482 - val_loss: 0.1473\n",
            "Epoch 26/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1482 - val_loss: 0.1470\n",
            "Epoch 27/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1487 - val_loss: 0.1477\n",
            "Epoch 28/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1473 - val_loss: 0.1464\n",
            "Epoch 29/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1476 - val_loss: 0.1466\n",
            "Epoch 30/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1483 - val_loss: 0.1474\n",
            "Epoch 31/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1491 - val_loss: 0.1464\n",
            "Epoch 32/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1466 - val_loss: 0.1464\n",
            "Epoch 33/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1467 - val_loss: 0.1459\n",
            "Epoch 34/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1472 - val_loss: 0.1554\n",
            "Epoch 35/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1464 - val_loss: 0.1470\n",
            "Epoch 36/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1471 - val_loss: 0.1468\n",
            "Epoch 37/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1467 - val_loss: 0.1463\n",
            "Epoch 38/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1473 - val_loss: 0.1459\n",
            "Epoch 39/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1458 - val_loss: 0.1473\n",
            "Epoch 40/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1461 - val_loss: 0.1466\n",
            "Epoch 41/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1470 - val_loss: 0.1452\n",
            "Epoch 42/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1449 - val_loss: 0.1451\n",
            "Epoch 43/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1453 - val_loss: 0.1484\n",
            "Epoch 44/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1467 - val_loss: 0.1447\n",
            "Epoch 45/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1454 - val_loss: 0.1455\n",
            "Epoch 46/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1461 - val_loss: 0.1448\n",
            "Epoch 47/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1447 - val_loss: 0.1443\n",
            "Epoch 48/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1441 - val_loss: 0.1448\n",
            "Epoch 49/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1446 - val_loss: 0.1458\n",
            "Epoch 50/50\n",
            "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1453 - val_loss: 0.1445\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x723c71d1f310>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ------------- FITTING MODEL ------------\n",
        "autoencoder.fit(X_train, Y_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjhBqLuo4YZp",
        "outputId": "b91787ee-1bb5-4376-f531-449bb52815e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 814us/step\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step\n",
            "\u001b[1m3255/3255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step\n"
          ]
        }
      ],
      "source": [
        "# ------------- MODEL INFERENCE ------------\n",
        "encoder = Model(inputs=input_layer, outputs=decoded_4)\n",
        "X_train_encoded = encoder.predict(X_train)\n",
        "X_test_encoded = encoder.predict(X_test)\n",
        "X_encoded = encoder.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mae_encoded=0.27874597916366606\n"
          ]
        }
      ],
      "source": [
        "# Compute nearest neighbors in the encoded space\n",
        "nbrs_encoded = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(X_train_encoded)\n",
        "distances_encoded, indices_encoded = nbrs_encoded.kneighbors(X_test_encoded)\n",
        "\n",
        "# Compute treatment effect using nearest neighbors in the encoded space\n",
        "treatment_effect_encoded = np.abs(Y_test.values - Y_train.iloc[indices_encoded.flatten()])\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae_encoded = mean_absolute_error(Y_test, treatment_effect_encoded)\n",
        "print(f\"{mae_encoded=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Evaluating Each Method (PCA, Manifold and Autoencoder) based on the paper**\n",
        "\n",
        "\n",
        "Next, to compare B. manifold learning and C. autoencoders, We also compute the estimated treatment effect for each point (ITE), and the average absolute error of ITE for B. manifold learning and C. Autoencoder, over all the data points in the test set.\n",
        "- Mean Absolute error (ITE,autoencoder: 3.7127,\n",
        "- Mean absolute error (ITE, Manifold learning): 4.4540\n",
        "- Thus, autoencoder error is 20.27% lesser than manifold learning estimate for the ITE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.28378702770176195"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mae_pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.27874597916366606"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mae_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generalized Neighbor Matching using Autoencoders\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Methods</th>\n",
              "      <th>Mean Absolute Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PCA</td>\n",
              "      <td>0.283787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Autoencoder</td>\n",
              "      <td>0.278746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Methods  Mean Absolute Error\n",
              "0          PCA             0.283787\n",
              "1  Autoencoder             0.278746"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Generalized Neighbor Matching using Autoencoders\")\n",
        "pd.DataFrame({\"Methods\": [\"PCA\", \"Autoencoder\"],\n",
        "              \"Mean Absolute Error\": [mae_pca, mae_encoded]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYA1U_1Frm-e"
      },
      "source": [
        "### 2. **Deep Neural Networks (DNNs) for Propensity Score Matching**\n",
        "\n",
        "Propensity score matching is a popular technique, but traditionally uses logistic regression for propensity score estimation. The paper proposes using deep neural network classifiers instead, presenting a model called PropensityNet.\n",
        "\n",
        "The key points are:\n",
        "\n",
        "* DNNs can potentially capture complex non-linear relationships better than logistic regression\n",
        "* PropensityNet is trained to estimate propensity scores as a binary classification problem\n",
        "* Experiments show PropensityNet outperforms logistic regression for propensity score estimation\n",
        "* This leads to better matching of treated and untreated units for ITE calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "LF3O2QTIrm-e"
      },
      "outputs": [],
      "source": [
        "# Regular Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter = 10000).fit(X_train, Y_train)\n",
        "preds = log_reg.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfCxm6tarm-e",
        "outputId": "5226bc40-87fe-48f5-9cd5-2d8c771083cd"
      },
      "outputs": [],
      "source": [
        "# assuming a 0.5 threshold\n",
        "accuracy_score_logistic_regression = accuracy_score(Y_test, (preds[:, 1] > 0.5).astype('int'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mae\n",
        "mae_logistic_regression = mean_absolute_error(Y_test, (preds[:, 1] > 0.5).astype('int'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4PsLvPprm-e",
        "outputId": "2d4fa9a8-205e-4168-bfec-3131f9db8017"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7379134860050891"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score_logistic_regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.26208651399491095"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mae_logistic_regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIC203Xcrm-e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.python/current/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7197 - loss: 0.6931\n",
            "Epoch 2/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7820 - loss: 0.5139\n",
            "Epoch 3/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7932 - loss: 0.4951\n",
            "Epoch 4/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7955 - loss: 0.4853\n",
            "Epoch 5/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7959 - loss: 0.4807\n",
            "Epoch 6/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7979 - loss: 0.4745\n",
            "Epoch 7/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7984 - loss: 0.4740\n",
            "Epoch 8/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7974 - loss: 0.4715\n",
            "Epoch 9/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7971 - loss: 0.4704\n",
            "Epoch 10/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7962 - loss: 0.4703\n",
            "Epoch 11/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8025 - loss: 0.4643\n",
            "Epoch 12/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8007 - loss: 0.4619\n",
            "Epoch 13/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7977 - loss: 0.4667\n",
            "Epoch 14/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4662\n",
            "Epoch 15/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7998 - loss: 0.4633\n",
            "Epoch 16/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8011 - loss: 0.4642\n",
            "Epoch 17/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8017 - loss: 0.4609\n",
            "Epoch 18/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8017 - loss: 0.4623\n",
            "Epoch 19/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4667\n",
            "Epoch 20/20\n",
            "\u001b[1m2604/2604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8011 - loss: 0.4604\n"
          ]
        }
      ],
      "source": [
        "# -------------- PROPENSITY NET (TensorFlow) --------------------\n",
        "\n",
        "# Define the model using the Sequential API\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(11,), activation='relu'),  # Input layer with 11 features and first hidden layer with 64 neurons\n",
        "    Dense(64, activation='relu'),  # Second hidden layer\n",
        "    Dense(64, activation='relu'),  # Third hidden layer\n",
        "    Dense(32, activation='relu'),  # Fourth hidden layer\n",
        "    Dense(16, activation='relu'),  # Fifth hidden layer\n",
        "    Dropout(0.3),  # Dropout layer\n",
        "    Dense(1, activation='sigmoid')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model with binary cross-entropy loss and the Adam optimizer\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])  # Include accuracy if you want to monitor it during training\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, epochs=20)  # Specify the number of epochs according to your training needs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwNjgoS2rm-f",
        "outputId": "02851ad3-e9ec-4527-c7e1-e0224a00f6b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step\n"
          ]
        }
      ],
      "source": [
        "preds_dnn = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy_score_propensity_net = accuracy_score(Y_test, (np.squeeze(preds_dnn) > 0.5).astype('int'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae_propensity_net = mean_absolute_error(Y_test, (np.squeeze(preds_dnn) > 0.5).astype('int'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzhlGHYcrm-f"
      },
      "source": [
        "#### **Evaluating Each Method (LogisticRegression, PropensityNet) based on the paper**\n",
        "\n",
        "\n",
        "- Evaluate them based on accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DNN for Propensity Score Matching\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>Mean Absolute Misclassification Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Propensity Net</td>\n",
              "      <td>0.803639</td>\n",
              "      <td>0.196361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.737913</td>\n",
              "      <td>0.262087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Method  Accuracy Score  Mean Absolute Misclassification Error\n",
              "0       Propensity Net        0.803639                               0.196361\n",
              "1  Logistic Regression        0.737913                               0.262087"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('DNN for Propensity Score Matching')\n",
        "pd.DataFrame({'Method': ['Propensity Net', 'Logistic Regression'],\n",
        "              'Accuracy Score': [accuracy_score_propensity_net, accuracy_score_logistic_regression ],\n",
        "              'Mean Absolute Misclassification Error': [mae_propensity_net, mae_logistic_regression]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame({'Method': ['Propensity Net', 'Logistic Regression'],\n",
        "              'Accuracy Score': [accuracy_score_propensity_net, accuracy_score_logistic_regression ],\n",
        "              'Mean Absolute Misclassification Error': [mae_propensity_net, mae_logistic_regression]}).plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m768\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,141</span> (137.27 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,141\u001b[0m (137.27 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,713</span> (45.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,713\u001b[0m (45.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,428</span> (91.52 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m23,428\u001b[0m (91.52 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Other code (ignore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model = nn.Sequential(\n",
        "#                 nn.Linear(in_features=11, out_features=64),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Linear(in_features=64, out_features=64),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Linear(in_features=64, out_features=64),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Linear(in_features=64, out_features=32),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Linear(in_features=32, out_features=16),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Dropout(p=0.3),\n",
        "#                 nn.Linear(in_features=16, out_features=1),\n",
        "#                 nn.Sigmoid()\n",
        "#             )\n",
        "\n",
        "\n",
        "# # -------------- LOSS FUNCTION (Binaty Cross Entropy) & OPTIMIZER (Adam) --------------------\n",
        "# criterion = nn.BCELoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# # ------- Tensors & Dataloaders --------------\n",
        "# # converting to pytorch tensors\n",
        "# X_tensor = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
        "# y_tensor = torch.tensor(y.to_numpy(), dtype=torch.float32)\n",
        "\n",
        "# # Dataloaders\n",
        "# train_dataset = TensorDataset(X_tensor, y_tensor)\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=220, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# total_params = sum(p.numel() for p in model.parameters())\n",
        "# print(\"Total number of parameters:\", total_params)\n",
        "\n",
        "\n",
        "\n",
        "# -------------- TRAINING LOOP --------------------\n",
        "\n",
        "# EPOCHS = 20\n",
        "# for epoch in range(EPOCHS):\n",
        "#     epoch_loss = 0\n",
        "#     for inputs, label in train_dataloader:\n",
        "\n",
        "#         # ---- FORWARD PASS -----\n",
        "#         pred = model(inputs)\n",
        "#         pred = pred.squeeze(1)\n",
        "#         loss = criterion(pred, label)\n",
        "\n",
        "#         # ----- BACKPROPAGATION -----\n",
        "#         loss.backward() # calculating gradients\n",
        "#         optimizer.step() # multiplies learning_rate * gradient, which is your step size or by how much you update the weights\n",
        "\n",
        "#         # loss\n",
        "#         epoch_loss += loss.item()\n",
        "#     epoch_loss /= len(train_dataloader)\n",
        "#     print(\"epoch: {0} training loss {1}\".format(epoch, epoch_loss))\n",
        "\n",
        "\n",
        "\n",
        "# -------------- EVALUATING MODEL --------------------\n",
        "# # Make predictions\n",
        "# model.eval()  # Set the model to evaluation mode\n",
        "# predictions = []\n",
        "# with torch.no_grad():  # Disable gradient tracking during inference\n",
        "#     for batch in train_dataloader:\n",
        "#         inputs, labels = batch\n",
        "#         pred = model(inputs)\n",
        "#         pred = pred.squeeze(1)  # If your model outputs a single value per sample\n",
        "#         predictions.append(pred)\n",
        "\n",
        "\n",
        "# # Concatenate predictions into a single tensor\n",
        "# predictions_tensor = torch.cat(predictions)\n",
        "\n",
        "# # Convert predictions to numpy array\n",
        "# predictions_array = predictions_tensor.numpy()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "usc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
