{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mdBU5Hgrm-a"
      },
      "source": [
        "## **Deep Learning for Causal Inference by Vikas Ramachandra**\n",
        "\n",
        "Applying the concepts from the \"Deep Learning for Causal Inference\" paper authored by Vikas Ramachandra to the data_for_churn_analysis dataset\n",
        "\n",
        "link to the paper: <a>https://arxiv.org/abs/1803.00149</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zvpIJP04rm-c"
      },
      "outputs": [],
      "source": [
        "# DA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ML\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_percentage_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8SYz7N7arm-c"
      },
      "outputs": [],
      "source": [
        "# Loading dataset\n",
        "df = pd.read_csv('data_for_churn_analysis.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQKDeQ46rm-c",
        "outputId": "01ef1e30-1f8f-41d5-bca9-9d79d6541ea1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104143, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX90IDW1rm-d",
        "outputId": "3390709e-219a-45c7-c323-78f05b7af7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 104143 entries, 0 to 104142\n",
            "Data columns (total 18 columns):\n",
            " #   Column                                 Non-Null Count   Dtype  \n",
            "---  ------                                 --------------   -----  \n",
            " 0   device                                 104025 non-null  object \n",
            " 1   first_payment_amount                   104143 non-null  int64  \n",
            " 2   age                                    104001 non-null  float64\n",
            " 3   city                                   98301 non-null   object \n",
            " 4   number_of_cards                        103671 non-null  float64\n",
            " 5   payments_initiated                     103671 non-null  float64\n",
            " 6   payments_failed                        103671 non-null  float64\n",
            " 7   payments_completed                     103671 non-null  float64\n",
            " 8   payments_completed_amount_first_7days  103671 non-null  float64\n",
            " 9   reward_purchase_count_first_7days      80879 non-null   float64\n",
            " 10  coins_redeemed_first_7days             103671 non-null  float64\n",
            " 11  is_referral                            104143 non-null  bool   \n",
            " 12  visits_feature_1                       101497 non-null  float64\n",
            " 13  visits_feature_2                       101497 non-null  float64\n",
            " 14  given_permission_1                     104143 non-null  int64  \n",
            " 15  given_permission_2                     104143 non-null  int64  \n",
            " 16  user_id                                104143 non-null  int64  \n",
            " 17  is_churned                             104143 non-null  int64  \n",
            "dtypes: bool(1), float64(10), int64(5), object(2)\n",
            "memory usage: 13.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoV-zMYgrm-d",
        "outputId": "6ee32d34-d178-41fe-b445-5f2b3a71fbf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df.isnull().sum().sum()=37490\n",
            "perc of dataset missing 0.3599857887712088\n"
          ]
        }
      ],
      "source": [
        "# null values?\n",
        "print(f\"{df.isnull().sum().sum()=}\")\n",
        "print(f\"perc of dataset missing {df.isnull().sum().sum()/df.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgvZy3Ujrm-d",
        "outputId": "dc2db3e3-9894-4da7-c8f6-095aba179535"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "is_churned\n",
              "0    0.713192\n",
              "1    0.286808\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# proportion of people who have churned\n",
        "df['is_churned'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EqFfmVArm-d"
      },
      "source": [
        "### 1. **Impact of Referrals on Customer Acquisition and Retention**:\n",
        "   - Research Question: Do customers acquired through referrals (`is_referral`) exhibit different behaviors and retention rates compared to non-referred customers?\n",
        "   - Treatment: Customer acquisition through referrals\n",
        "   - Outcome: Customer behavior (e.g., `payments_initiated`, `payments_completed`, `visits_feature_1`, `visits_feature_2`) and churn (`is_churned`)\n",
        "   - Potential Confounders: `device`, `age`, `city`, `number_of_cards`, `payments_failed`, `payments_completed_amount_first_7days`, `reward_purchase_count_first_7days`, `coins_redeemed_first_7days`, `given_permission_1`, `given_permission_2`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEakGKKlrm-d"
      },
      "source": [
        "$$Y_i = f(T_i, X_i, \\epsilon_i)$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $Y_i$ represents the outcome variable `is_churned` for customer $i$\n",
        "- $T_i$ is the treatment variable `is_referral`, indicating whether customer $i$ was acquired through a referral\n",
        "- $X_i$ represents the vector of potential confounding variables for customer $i$, such as `device`, `age`, `city`, `number_of_cards`, `payments_failed`, `payments_completed_amount_first_7days`, `reward_purchase_count_first_7days`, `coins_redeemed_first_7days`, `given_permission_1`, `given_permission_2`\n",
        "- $\\epsilon_i$ is the error term, accounting for unobserved factors affecting the outcome\n",
        "- $f$ is an unknown function that maps the treatment, confounders, and error term to the outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Xvw_7xl1rm-d"
      },
      "outputs": [],
      "source": [
        "# -------------- DATA PREPROCESSING --------------------\n",
        "\n",
        "# Encoding using label encoding technique\n",
        "obj_cols = df.select_dtypes(include='object').columns # grabs object dtypes columns\n",
        "le = LabelEncoder() # creates LabelEncoder instance\n",
        "for col in obj_cols:\n",
        "    df[col] = le.fit_transform(df[col]) # encodes each column\n",
        "\n",
        "df['is_referral'] = np.where(df['is_referral'] == True, 1, 0)\n",
        "\n",
        "\n",
        "# -------------- IMPUTING MISSING VALUES --------------------\n",
        "missing_cols = df.columns[df.isna().any()].tolist()\n",
        "for col in missing_cols:\n",
        "    df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "\n",
        "# -------------- DATA SPLIT --------------------\n",
        "\n",
        "confounders = [\n",
        "    'device',\n",
        "    'age',\n",
        "    'city',\n",
        "    'number_of_cards',\n",
        "    'payments_failed',\n",
        "    'payments_completed_amount_first_7days',\n",
        "    'reward_purchase_count_first_7days',\n",
        "    'coins_redeemed_first_7days',\n",
        "    'given_permission_1',\n",
        "    'given_permission_2',\n",
        "    'is_referral' # treatment\n",
        "]\n",
        "\n",
        "y = df['is_churned']\n",
        "X = df[confounders]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "Y_train, Y_test = train_test_split(y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaMEkZ6rrm-e"
      },
      "source": [
        "### 1. **Generalized Neighbor Matching using Autoencoders**\n",
        "\n",
        "The paper proposes using autoencoders, a type of deep neural network, for dimensionality reduction while preserving the local neighborhood structure of the data. This is useful for generalized neighbor matching to estimate individual treatment effects (ITEs).\n",
        "\n",
        "The key points are:\n",
        "\n",
        "* In high dimensions, traditional neighbor matching methods like k-nearest neighbors struggle\n",
        "* Autoencoders can learn a low-dimensional representation that captures the manifold structure\n",
        "* This low-dimensional encoding preserves local neighborhoods for accurate neighbor identification\n",
        "* Experiments show autoencoders outperform methods like manifold learning for ITE estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xG-bQR2w4JUY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VastVKpxrm-e"
      },
      "outputs": [],
      "source": [
        "input_dim = X.shape[1]  # Features count\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "\n",
        "# Encoder: Reduce dimensionality\n",
        "encoded_1 = Dense(64, activation='relu')(input_layer)\n",
        "encoded_2 = Dense(32, activation='relu')(encoded_1)\n",
        "encoded_3 = Dense(16, activation='relu')(encoded_2)\n",
        "encoded_4 = Dense(8, activation='relu')(encoded_3)\n",
        "\n",
        "# Decoder: Reconstruct the input\n",
        "decoded_1 = Dense(16, activation='relu')(encoded_4)\n",
        "decoded_2 = Dense(32, activation='relu')(decoded_1)\n",
        "decoded_3 = Dense(64, activation='relu')(decoded_2)\n",
        "decoded_4 = Dense(input_dim, activation='linear')(decoded_3)  # Final output layer\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoded_4)  # Ensure to output from the last decoding layer\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey_7YBXBrm-e",
        "outputId": "54495b78-0028-4fab-8c5e-7682dadaff50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "326/326 [==============================] - 3s 4ms/step - loss: 0.2252 - val_loss: 18916.6152\n",
            "Epoch 2/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1641 - val_loss: 18919.7578\n",
            "Epoch 3/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1580 - val_loss: 18917.5625\n",
            "Epoch 4/50\n",
            "326/326 [==============================] - 2s 5ms/step - loss: 0.1555 - val_loss: 18914.0742\n",
            "Epoch 5/50\n",
            "326/326 [==============================] - 2s 6ms/step - loss: 0.1544 - val_loss: 18915.3496\n",
            "Epoch 6/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1525 - val_loss: 18914.1914\n",
            "Epoch 7/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1521 - val_loss: 18918.8926\n",
            "Epoch 8/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1518 - val_loss: 18919.3516\n",
            "Epoch 9/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1506 - val_loss: 18918.0723\n",
            "Epoch 10/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1507 - val_loss: 18910.7578\n",
            "Epoch 11/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1510 - val_loss: 18917.3340\n",
            "Epoch 12/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1500 - val_loss: 18914.2422\n",
            "Epoch 13/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1494 - val_loss: 18908.5840\n",
            "Epoch 14/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1500 - val_loss: 18910.9082\n",
            "Epoch 15/50\n",
            "326/326 [==============================] - 2s 6ms/step - loss: 0.1491 - val_loss: 18919.1797\n",
            "Epoch 16/50\n",
            "326/326 [==============================] - 2s 5ms/step - loss: 0.1492 - val_loss: 18914.7344\n",
            "Epoch 17/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1486 - val_loss: 18913.3320\n",
            "Epoch 18/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1485 - val_loss: 18918.2344\n",
            "Epoch 19/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1482 - val_loss: 18919.3789\n",
            "Epoch 20/50\n",
            "326/326 [==============================] - 1s 4ms/step - loss: 0.1486 - val_loss: 18917.6035\n",
            "Epoch 21/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1488 - val_loss: 18909.3906\n",
            "Epoch 22/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1478 - val_loss: 18915.0352\n",
            "Epoch 23/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1476 - val_loss: 18913.4473\n",
            "Epoch 24/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1474 - val_loss: 18919.3613\n",
            "Epoch 25/50\n",
            "326/326 [==============================] - 1s 4ms/step - loss: 0.1477 - val_loss: 18912.8633\n",
            "Epoch 26/50\n",
            "326/326 [==============================] - 2s 5ms/step - loss: 0.1470 - val_loss: 18912.0254\n",
            "Epoch 27/50\n",
            "326/326 [==============================] - 1s 4ms/step - loss: 0.1466 - val_loss: 18917.0098\n",
            "Epoch 28/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1465 - val_loss: 18914.0625\n",
            "Epoch 29/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1465 - val_loss: 18915.1660\n",
            "Epoch 30/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1464 - val_loss: 18915.6836\n",
            "Epoch 31/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1462 - val_loss: 18917.0137\n",
            "Epoch 32/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1464 - val_loss: 18918.0488\n",
            "Epoch 33/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1465 - val_loss: 18915.8125\n",
            "Epoch 34/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1461 - val_loss: 18916.8027\n",
            "Epoch 35/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1458 - val_loss: 18919.3242\n",
            "Epoch 36/50\n",
            "326/326 [==============================] - 1s 4ms/step - loss: 0.1457 - val_loss: 18917.5020\n",
            "Epoch 37/50\n",
            "326/326 [==============================] - 2s 5ms/step - loss: 0.1458 - val_loss: 18916.2227\n",
            "Epoch 38/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1455 - val_loss: 18915.6035\n",
            "Epoch 39/50\n",
            "326/326 [==============================] - 1s 4ms/step - loss: 0.1453 - val_loss: 18917.8867\n",
            "Epoch 40/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1454 - val_loss: 18914.8730\n",
            "Epoch 41/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1452 - val_loss: 18913.4512\n",
            "Epoch 42/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1452 - val_loss: 18918.5996\n",
            "Epoch 43/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1452 - val_loss: 18915.0352\n",
            "Epoch 44/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1453 - val_loss: 18918.8066\n",
            "Epoch 45/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1451 - val_loss: 18914.7344\n",
            "Epoch 46/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1452 - val_loss: 18916.6797\n",
            "Epoch 47/50\n",
            "326/326 [==============================] - 2s 5ms/step - loss: 0.1451 - val_loss: 18916.0332\n",
            "Epoch 48/50\n",
            "326/326 [==============================] - 2s 5ms/step - loss: 0.1448 - val_loss: 18916.8750\n",
            "Epoch 49/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1447 - val_loss: 18916.5566\n",
            "Epoch 50/50\n",
            "326/326 [==============================] - 1s 3ms/step - loss: 0.1450 - val_loss: 18916.5781\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79686664acb0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "autoencoder.fit(X_train, Y_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjhBqLuo4YZp",
        "outputId": "880d0e55-a2f7-4310-f654-8af36869f440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2604/2604 [==============================] - 4s 1ms/step\n",
            "651/651 [==============================] - 1s 1ms/step\n",
            "3255/3255 [==============================] - 6s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "encoder = Model(inputs=input_layer, outputs=decoded_4)\n",
        "X_train_encoded = encoder.predict(X_train)\n",
        "X_test_encoded = encoder.predict(X_test)\n",
        "X_encoded = encoder.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = tf.keras.metrics.mean_absolute_error(X_test, X_test_encoded)\n",
        "print(\"Mean Absolute Error: \", mae.numpy().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc5tHloAeRhs",
        "outputId": "bab68f40-df1c-4b36-a9d0-5ae286f03733"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error:  47.731796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYA1U_1Frm-e"
      },
      "source": [
        "### 2. **Deep Neural Networks (DNNs) for Propensity Score Matching**\n",
        "\n",
        "Propensity score matching is a popular technique, but traditionally uses logistic regression for propensity score estimation. The paper proposes using deep neural network classifiers instead, presenting a model called PropensityNet.\n",
        "\n",
        "The key points are:\n",
        "\n",
        "* DNNs can potentially capture complex non-linear relationships better than logistic regression\n",
        "* PropensityNet is trained to estimate propensity scores as a binary classification problem\n",
        "* Experiments show PropensityNet outperforms logistic regression for propensity score estimation\n",
        "* This leads to better matching of treated and untreated units for ITE calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LF3O2QTIrm-e"
      },
      "outputs": [],
      "source": [
        "# Regular Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter = 10000).fit(X_train_encoded, Y_train)\n",
        "preds = log_reg.predict_proba(X_encoded)\n",
        "\n",
        "df_copy = df.copy()\n",
        "df_copy.loc[:, 'propensity_score'] = preds[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y, preds[:,1])\n",
        "print(f\"Mean Absolute Misclassification Error: {mae}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn1lGw6AMuUr",
        "outputId": "c7e18bb3-d5b5-4021-a176-d981f1467703"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Misclassification Error: 0.2873118659774708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "y_pred = (preds >= threshold).astype(int)\n",
        "\n",
        "# True labels\n",
        "y_true = y  # Assuming y_test contains the true labels\n",
        "\n",
        "# Misassignments\n",
        "misassignments = (np.sum(y_pred[:,1] != y_true)/len(y_true))*100\n",
        "print(f\"Number of Misassignments percentage: {misassignments}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9PfT7meOAfz",
        "outputId": "b6fab263-dfb5-4902-e1fc-91d5fe047829"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Misassignments percentage: 19.511633043027377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v46JY7e7rm-e",
        "outputId": "c2c8d98d-f70f-49d5-d45c-ce92baef42a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "is_churned\n",
              "0    0.201751\n",
              "1    0.499927\n",
              "Name: propensity_score, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "df_copy.groupby('is_churned')['propensity_score'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfCxm6tarm-e",
        "outputId": "5b6eb3c3-461d-4283-dbb4-e2a52390e37e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8048836695697262"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# assuming a 0.5 threshold\n",
        "accuracy_score(y, (preds[:, 1] > 0.5).astype('int'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch-uUHVXrm-e",
        "outputId": "bb722574-1ce7-49a6-c88a-df251a50dc9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104143, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the model using the Sequential API\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(11,), activation='relu'),  # Input layer with 11 features and first hidden layer with 64 neurons\n",
        "    Dense(64, activation='relu'),  # Second hidden layer\n",
        "    Dense(64, activation='relu'),  # Third hidden layer\n",
        "    Dense(32, activation='relu'),  # Fourth hidden layer\n",
        "    Dense(16, activation='relu'),  # Fifth hidden layer\n",
        "    Dropout(0.3),  # Dropout layer\n",
        "    Dense(1, activation='sigmoid')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model with binary cross-entropy loss and the Adam optimizer\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])  # Include accuracy if you want to monitor it during training\n"
      ],
      "metadata": {
        "id": "8gKl-XcbFvgt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_encoded, Y_train, epochs=50)  # Specify the number of epochs according to your training needs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyuFD3ByGHhy",
        "outputId": "f88e0eb8-51dd-4238-d30f-6491d20fb5eb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2604/2604 [==============================] - 8s 3ms/step - loss: 0.4728 - accuracy: 0.8020\n",
            "Epoch 2/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4641 - accuracy: 0.8032\n",
            "Epoch 3/50\n",
            "2604/2604 [==============================] - 9s 3ms/step - loss: 0.4631 - accuracy: 0.8033\n",
            "Epoch 4/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4631 - accuracy: 0.8025\n",
            "Epoch 5/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4631 - accuracy: 0.8025\n",
            "Epoch 6/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4632 - accuracy: 0.8022\n",
            "Epoch 7/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4625 - accuracy: 0.8025\n",
            "Epoch 8/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4630 - accuracy: 0.8023\n",
            "Epoch 9/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4622 - accuracy: 0.8024\n",
            "Epoch 10/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4621 - accuracy: 0.8018\n",
            "Epoch 11/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4630 - accuracy: 0.8020\n",
            "Epoch 12/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4629 - accuracy: 0.8015\n",
            "Epoch 13/50\n",
            "2604/2604 [==============================] - 8s 3ms/step - loss: 0.4626 - accuracy: 0.8020\n",
            "Epoch 14/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4617 - accuracy: 0.8017\n",
            "Epoch 15/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4619 - accuracy: 0.8019\n",
            "Epoch 16/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4612 - accuracy: 0.8029\n",
            "Epoch 17/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4621 - accuracy: 0.8018\n",
            "Epoch 18/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4613 - accuracy: 0.8016\n",
            "Epoch 19/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4618 - accuracy: 0.8014\n",
            "Epoch 20/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4629 - accuracy: 0.8024\n",
            "Epoch 21/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4618 - accuracy: 0.8023\n",
            "Epoch 22/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4618 - accuracy: 0.8020\n",
            "Epoch 23/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4627 - accuracy: 0.8011\n",
            "Epoch 24/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4626 - accuracy: 0.8018\n",
            "Epoch 25/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4619 - accuracy: 0.8022\n",
            "Epoch 26/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4613 - accuracy: 0.8021\n",
            "Epoch 27/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4625 - accuracy: 0.8016\n",
            "Epoch 28/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4615 - accuracy: 0.8018\n",
            "Epoch 29/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4617 - accuracy: 0.8021\n",
            "Epoch 30/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4615 - accuracy: 0.8021\n",
            "Epoch 31/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4613 - accuracy: 0.8020\n",
            "Epoch 32/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4618 - accuracy: 0.8016\n",
            "Epoch 33/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4611 - accuracy: 0.8027\n",
            "Epoch 34/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4610 - accuracy: 0.8028\n",
            "Epoch 35/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4610 - accuracy: 0.8026\n",
            "Epoch 36/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4615 - accuracy: 0.8022\n",
            "Epoch 37/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4622 - accuracy: 0.8037\n",
            "Epoch 38/50\n",
            "2604/2604 [==============================] - 8s 3ms/step - loss: 0.4612 - accuracy: 0.8024\n",
            "Epoch 39/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4614 - accuracy: 0.8026\n",
            "Epoch 40/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4610 - accuracy: 0.8025\n",
            "Epoch 41/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4616 - accuracy: 0.8017\n",
            "Epoch 42/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4614 - accuracy: 0.8025\n",
            "Epoch 43/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4607 - accuracy: 0.8023\n",
            "Epoch 44/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4614 - accuracy: 0.8022\n",
            "Epoch 45/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4613 - accuracy: 0.8032\n",
            "Epoch 46/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4606 - accuracy: 0.8025\n",
            "Epoch 47/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4613 - accuracy: 0.8020\n",
            "Epoch 48/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4619 - accuracy: 0.8026\n",
            "Epoch 49/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4610 - accuracy: 0.8018\n",
            "Epoch 50/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4610 - accuracy: 0.8026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIC203Xcrm-e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_dnn = model.predict(X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzNpnkByG5Im",
        "outputId": "d3f06d9a-fd96-4da6-a2cd-181d8e2d7f6f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3255/3255 [==============================] - 5s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds_dnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10LW5s5eHF4m",
        "outputId": "ff14d8c3-b4be-4a08-f83c-453941bd1c32"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.81726485]\n",
            " [0.904208  ]\n",
            " [0.382405  ]\n",
            " ...\n",
            " [0.38969007]\n",
            " [0.13030174]\n",
            " [0.08892549]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_dnn = np.squeeze(preds_dnn)\n",
        "print(preds_dnn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hWVSAwFciZP",
        "outputId": "3eb1b13e-4b24-41fd-9ac8-fdedc0685796"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(104143,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Assuming y_pred_probs are the predicted probabilities and y_true are the actual labels  # Output of the model's sigmoid function\n",
        "y_true = y                       # Actual labels\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(y_true, preds_dnn)\n",
        "print(f\"Mean Absolute Classification Error: {mae}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK3WipISc3ii",
        "outputId": "a06f33ae-b992-4882-c6ce-6c984e6f3754"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Classification Error: 0.3039754900891989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "y_pred = (preds_dnn >= threshold).astype(int)\n",
        "# True labels\n",
        "y_true = np.array(y) # Assuming y_test contains the true labels\n",
        "# Misassignments\n",
        "misassignments = (np.sum(y_pred != y_true)/len(y_true))*100\n",
        "print(f\"Number of Misassignments percentage: {misassignments}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I7Gq83FPPK8",
        "outputId": "40c134e0-a0f9-4b02-b154-d55dee7a875d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Misassignments percentage: 19.524115879127738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assuming a 0.5 threshold\n",
        "accuracy_score(y, (preds_dnn > 0.5).astype('int'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_n6L9H2HNZx",
        "outputId": "8bbf74cc-cc1f-40ae-b5e5-a6f3ac71fdce"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8047588412087227"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fec_BwbaiBpk",
        "outputId": "9dffa5cc-9c05-49d7-e8ea-a333295905ea"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras_tuner import HyperModel, RandomSearch\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential([\n",
        "        Dense(units=hp.Int('units_1', min_value=32, max_value=128, step=32),\n",
        "              input_shape=(11,),\n",
        "              activation='relu'),\n",
        "        Dense(units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n",
        "              activation='relu'),\n",
        "        Dense(units=hp.Int('units_3', min_value=32, max_value=128, step=32),\n",
        "              activation='relu'),\n",
        "        Dense(units=hp.Int('units_4', min_value=16, max_value=64, step=16),\n",
        "              activation='relu'),\n",
        "        Dense(units=hp.Int('units_5', min_value=16, max_value=64, step=16),\n",
        "              activation='relu'),\n",
        "        Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "46bYy5M7iNNA"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,\n",
        "    executions_per_trial=1,\n",
        "    directory='propnet_dnn_tuning',\n",
        "    project_name='Deep_Learning'\n",
        ")\n",
        "\n",
        "# Optional: Define a callback to clear the training outputs at the end of every training step.\n",
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "    def on_train_end(*args, **kwargs):\n",
        "        from IPython.display import clear_output\n",
        "        clear_output(wait=True)"
      ],
      "metadata": {
        "id": "8dfcvKFgjHuj"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x=X_train_encoded, y=Y_train,\n",
        "             epochs=50,\n",
        "             batch_size=256,\n",
        "             validation_data=(X_test_encoded, Y_test),\n",
        "             callbacks=[ClearTrainingOutput()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gFmK_avjLCN",
        "outputId": "2b99399c-bd83-4f30-c620-e68eacaba602"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 01m 22s]\n",
            "val_accuracy: 0.806279718875885\n",
            "\n",
            "Best val_accuracy So Far: 0.8064237236976624\n",
            "Total elapsed time: 00h 33m 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "loss, accuracy = best_model.evaluate(X_test_encoded, Y_test)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tb-yWkDl9o4",
        "outputId": "7e04f3b9-7b16-48a3-8ba2-2fdf257c39a3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "651/651 [==============================] - 1s 2ms/step - loss: 0.4527 - accuracy: 0.8064\n",
            "Loss: 0.4527221620082855, Accuracy: 0.8064237236976624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"Best hyperparameters found:\")\n",
        "for param, value in best_hyperparameters.values.items():\n",
        "    print(f\"{param}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK9M9zWjwms_",
        "outputId": "3b679aa4-33e7-4935-9311-8b5b3556bd42"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters found:\n",
            "units_1: 96\n",
            "units_2: 96\n",
            "units_3: 64\n",
            "units_4: 16\n",
            "units_5: 32\n",
            "dropout: 0.1\n",
            "learning_rate: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLKqLdGKtjZM",
        "outputId": "3e5eebc2-9556-40eb-eb9d-371f20d3574b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 96)                1152      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 96)                9312      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                6208      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18289 (71.44 KB)\n",
            "Trainable params: 18289 (71.44 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the best model using the Sequential API\n",
        "model = Sequential([\n",
        "    Dense(96, input_shape=(11,), activation='relu'),  # Input layer with 11 features and first hidden layer with 64 neurons\n",
        "    Dense(96, activation='relu'),  # Second hidden layer\n",
        "    Dense(64, activation='relu'),  # Third hidden layer\n",
        "    Dense(16, activation='relu'),  # Fourth hidden layer\n",
        "    Dense(32, activation='relu'),  # Fifth hidden layer\n",
        "    Dropout(0.1),  # Dropout layer\n",
        "    Dense(1, activation='sigmoid')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model with binary cross-entropy loss and the Adam optimizer\n",
        "model.compile(optimizer=Adam(learning_rate=0.01),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])  # Include accuracy if you want to monitor it during training"
      ],
      "metadata": {
        "id": "G3SEUJX2tq70"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_encoded, Y_train, epochs=50)  # Specify the number of epochs according to your training needs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubJhPGLww9rJ",
        "outputId": "ef133074-e089-44f0-ea66-4ec7c9c7a61c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2604/2604 [==============================] - 10s 3ms/step - loss: 0.4653 - accuracy: 0.8015\n",
            "Epoch 2/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4613 - accuracy: 0.8025\n",
            "Epoch 3/50\n",
            "2604/2604 [==============================] - 9s 4ms/step - loss: 0.4608 - accuracy: 0.8020\n",
            "Epoch 4/50\n",
            "2604/2604 [==============================] - 10s 4ms/step - loss: 0.4607 - accuracy: 0.8033\n",
            "Epoch 5/50\n",
            "2604/2604 [==============================] - 11s 4ms/step - loss: 0.4600 - accuracy: 0.8030\n",
            "Epoch 6/50\n",
            "2604/2604 [==============================] - 12s 5ms/step - loss: 0.4597 - accuracy: 0.8029\n",
            "Epoch 7/50\n",
            "2604/2604 [==============================] - 9s 3ms/step - loss: 0.4594 - accuracy: 0.8028\n",
            "Epoch 8/50\n",
            "2604/2604 [==============================] - 9s 3ms/step - loss: 0.4599 - accuracy: 0.8025\n",
            "Epoch 9/50\n",
            "2604/2604 [==============================] - 8s 3ms/step - loss: 0.4603 - accuracy: 0.8028\n",
            "Epoch 10/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4592 - accuracy: 0.8037\n",
            "Epoch 11/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4598 - accuracy: 0.8031\n",
            "Epoch 12/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4596 - accuracy: 0.8026\n",
            "Epoch 13/50\n",
            "2604/2604 [==============================] - 8s 3ms/step - loss: 0.4603 - accuracy: 0.8024\n",
            "Epoch 14/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4597 - accuracy: 0.8034\n",
            "Epoch 15/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4596 - accuracy: 0.8027\n",
            "Epoch 16/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4594 - accuracy: 0.8030\n",
            "Epoch 17/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4593 - accuracy: 0.8033\n",
            "Epoch 18/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4596 - accuracy: 0.8024\n",
            "Epoch 19/50\n",
            "2604/2604 [==============================] - 8s 3ms/step - loss: 0.4588 - accuracy: 0.8036\n",
            "Epoch 20/50\n",
            "2604/2604 [==============================] - 7s 2ms/step - loss: 0.4601 - accuracy: 0.8036\n",
            "Epoch 21/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4593 - accuracy: 0.8025\n",
            "Epoch 22/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4604 - accuracy: 0.8029\n",
            "Epoch 23/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4601 - accuracy: 0.8033\n",
            "Epoch 24/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4592 - accuracy: 0.8036\n",
            "Epoch 25/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4589 - accuracy: 0.8027\n",
            "Epoch 26/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4591 - accuracy: 0.8025\n",
            "Epoch 27/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4596 - accuracy: 0.8033\n",
            "Epoch 28/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4594 - accuracy: 0.8030\n",
            "Epoch 29/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4592 - accuracy: 0.8040\n",
            "Epoch 30/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4600 - accuracy: 0.8030\n",
            "Epoch 31/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4590 - accuracy: 0.8031\n",
            "Epoch 32/50\n",
            "2604/2604 [==============================] - 8s 3ms/step - loss: 0.4586 - accuracy: 0.8033\n",
            "Epoch 33/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4594 - accuracy: 0.8029\n",
            "Epoch 34/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4597 - accuracy: 0.8030\n",
            "Epoch 35/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4588 - accuracy: 0.8033\n",
            "Epoch 36/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4598 - accuracy: 0.8028\n",
            "Epoch 37/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4592 - accuracy: 0.8031\n",
            "Epoch 38/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4590 - accuracy: 0.8035\n",
            "Epoch 39/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4593 - accuracy: 0.8033\n",
            "Epoch 40/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4598 - accuracy: 0.8025\n",
            "Epoch 41/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4594 - accuracy: 0.8024\n",
            "Epoch 42/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4591 - accuracy: 0.8026\n",
            "Epoch 43/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4594 - accuracy: 0.8024\n",
            "Epoch 44/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4593 - accuracy: 0.8020\n",
            "Epoch 45/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4591 - accuracy: 0.8030\n",
            "Epoch 46/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4595 - accuracy: 0.8031\n",
            "Epoch 47/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4585 - accuracy: 0.8028\n",
            "Epoch 48/50\n",
            "2604/2604 [==============================] - 9s 3ms/step - loss: 0.4602 - accuracy: 0.8031\n",
            "Epoch 49/50\n",
            "2604/2604 [==============================] - 6s 2ms/step - loss: 0.4595 - accuracy: 0.8029\n",
            "Epoch 50/50\n",
            "2604/2604 [==============================] - 7s 3ms/step - loss: 0.4591 - accuracy: 0.8032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_dnn = model.predict(X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrlxkReSxCiH",
        "outputId": "6ffd8db6-c115-4e79-f352-1b9ccdfad64f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3255/3255 [==============================] - 5s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds_dnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN6GRjpsxFP4",
        "outputId": "e0ea6056-dd60-463e-d6b4-23379b6ca61b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.89484686]\n",
            " [0.9537522 ]\n",
            " [0.35540637]\n",
            " ...\n",
            " [0.37305328]\n",
            " [0.11928537]\n",
            " [0.09210102]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_dnn = np.squeeze(preds_dnn)\n",
        "print(preds_dnn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ByUsy26xH7W",
        "outputId": "3f2e24f4-5309-491c-c8b4-a0674cf817f2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(104143,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Assuming y_pred_probs are the predicted probabilities and y_true are the actual labels  # Output of the model's sigmoid function\n",
        "y_true = y                       # Actual labels\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(y_true, preds_dnn)\n",
        "print(f\"Mean Absolute Classification Error: {mae}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edh_94j7xK2K",
        "outputId": "b03323e6-f3f2-42a0-f3d3-77deb66f4797"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Classification Error: 0.2831783819328123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "y_pred = (preds_dnn >= threshold).astype(int)\n",
        "# True labels\n",
        "y_true = np.array(y) # Assuming y_test contains the true labels\n",
        "# Misassignments\n",
        "misassignments = (np.sum(y_pred != y_true)/len(y_true))*100\n",
        "print(f\"Number of Misassignments percentage: {misassignments}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPJUzyd3xOMd",
        "outputId": "d611c385-3db2-4582-91f1-9c1ce370ea7b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Misassignments percentage: 19.533718060743404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assuming a 0.5 threshold\n",
        "accuracy_score(y, (preds_dnn > 0.5).astype('int'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-udntlQBxQna",
        "outputId": "58b2338c-609b-4c16-e265-6f6def551f31"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.804662819392566"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaYJQ9yorm-l"
      },
      "source": [
        "# Deep Learning for Causal Inference\n",
        "\n",
        "This README summarizes the key points and contributions of the paper \"Deep Learning for Causal Inference\" by Vikas Ramachandra.\n",
        "\n",
        "## 1. Generalized Neighbor Matching using Autoencoders\n",
        "\n",
        "The paper proposes using autoencoders, a type of deep neural network, for dimensionality reduction while preserving the local neighborhood structure of the data. This is useful for generalized neighbor matching to estimate individual treatment effects (ITEs).\n",
        "\n",
        "The key points are:\n",
        "\n",
        "* In high dimensions, traditional neighbor matching methods like k-nearest neighbors struggle\n",
        "* Autoencoders can learn a low-dimensional representation that captures the manifold structure\n",
        "* This low-dimensional encoding preserves local neighborhoods for accurate neighbor identification\n",
        "* Experiments show autoencoders outperform methods like manifold learning for ITE estimation\n",
        "\n",
        "## 2. Deep Neural Networks (DNNs) for Propensity Score Matching\n",
        "\n",
        "Propensity score matching is a popular technique, but traditionally uses logistic regression for propensity score estimation. The paper proposes using deep neural network classifiers instead, presenting a model called PropensityNet.\n",
        "\n",
        "The key points are:\n",
        "\n",
        "* DNNs can potentially capture complex non-linear relationships better than logistic regression\n",
        "* PropensityNet is trained to estimate propensity scores as a binary classification problem\n",
        "* Experiments show PropensityNet outperforms logistic regression for propensity score estimation\n",
        "* This leads to better matching of treated and untreated units for ITE calculation\n",
        "\n",
        "## Overall Contribution\n",
        "\n",
        "The paper argues that deep learning models like autoencoders and DNNs can improve upon traditional methods for neighbor matching and propensity score estimation, two crucial steps in causal inference for estimating individual and average treatment effects.\n",
        "\n",
        "The main contributions are introducing these deep learning approaches, evaluating them on simulated datasets, and demonstrating their potential advantages over existing techniques through experimental results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrkMUUPOrm-l"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "usc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}